{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455eb6d1-4db4-4aa8-b15a-240fb742279f",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "# 🧠 Enhancing Large Language Models (LLMs) Using Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "\n",
    "## 🚀 **Introduction**\n",
    "\n",
    "This tutorial focuses on two key concepts:  \n",
    "\n",
    "1. **Large Language Models (LLMs)**:  \n",
    "   These are advanced artificial intelligence (AI) systems capable of understanding and generating human-like text. Examples include ChatGPT, GPT-4, and other AI tools that can process vast amounts of language data.  \n",
    "\n",
    "2. **Retrieval-Augmented Generation (RAG)**:  \n",
    "   RAG is a method that improves the capabilities of LLMs by integrating a retrieval system. This means the model can \"look up\" relevant information in a database or document repository while generating responses, making its answers more accurate and contextually rich.\n",
    "\n",
    "---\n",
    "\n",
    "By combining these two powerful tools, we can create systems that are not only intelligent but also capable of reasoning with real-world data and context. \n",
    "\n",
    "---\n",
    "\n",
    "### Why Learn This?\n",
    "\n",
    "🔍 **Understand RAG**: Learn how retrieval improves the performance of LLMs.  \n",
    "⚙️ **Hands-On Practice**: Build a practical system step-by-step.  \n",
    "🎯 **Beginner Friendly**: No prior experience needed—we’ll explain everything along the way!\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Need:\n",
    "- Basic knowledge of Python 🐍 (optional but helpful)  \n",
    "- A working Jupyter Notebook environment 📒  \n",
    "- Curiosity to learn something new! 🌟\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe51081-3e6d-4659-8bee-a11b13c4e23d",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\">\n",
    "<tr>\n",
    "<td style=\"vertical-align: top; text-align: left; width: 50%; font-size: 18px;\">\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [🧠 Step 1: Introduction and Prerequisites](#1)  \n",
    "2. [📦 Step 2: Importing and Explaining Required Libraries](#2)  \n",
    "3. [🔧 Step 3: Constants and Initial Setup](#3)  \n",
    "4. [🗄️ Step 4: Setting Up the Vector Database](#4)  \n",
    "5. [🔢 Step 5: Setting Up the Embedding Model](#5)  \n",
    "6. [🧹 Step 6: Cleaning and Processing Web Content](#6)  \n",
    "7. [✂️ Step 7: Splitting Text into Chunks](#7)  \n",
    "8. [💬 Step 8: Creating Chatbot Prompts](#8)  \n",
    "9. [🤖 Step 9: Initializing the Chatbot](#9)  \n",
    "10. [🏁 Step 10: Creating the Main Function](#10)  \n",
    "\n",
    "</td>\n",
    "<td style=\"text-align: center; width: 50%; font-size: 18px;\">\n",
    "\n",
    "### Chatbot Flowchart Diagram\n",
    "\n",
    "<img src=\"chatbot-flowchart.png\" alt=\"Chatbot Flowchart\" width=\"400\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49081a-7286-486d-b280-c1481e04861f",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 🧠 Step 1: Introduction and Prerequisites\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "\n",
    "## 🤔 What Are We Building?\n",
    "\n",
    "In this tutorial, we will create a **chatbot** that intelligently answers questions by retrieving relevant information from a website. The chatbot combines **Large Language Models (LLMs)** and a **vector database** for accurate and context-aware responses.\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ Key Features of the Chatbot:\n",
    "\n",
    "- 🌐 **Web Content Retrieval**: Extracts and processes data from a website.  \n",
    "- 🧠 **Contextual Answering**: Matches user queries with the most relevant content using embeddings.  \n",
    "- 📊 **Transparent Sources**: Provides references for its answers, ensuring trustworthiness.  \n",
    "- ⚙️ **Automated Setup**: A single script sets up everything for you!\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Prerequisites\n",
    "\n",
    "No need to install libraries or configure your environment manually! Everything is handled by the provided Docker script. Here's all you need:\n",
    "\n",
    "1. **Docker Installed**:  \n",
    "   - Ensure Docker is installed. If not, download it from [Docker's official website](https://www.docker.com/).  \n",
    "2. **Docker Port Availability**:  \n",
    "   - Ensure port `8888` is free. The script will automatically clean up this port if it's in use.  \n",
    "3. **Groq API Key**:  \n",
    "   - Obtain an API key to access Groq’s language model. Register [here](https://groq.com/).\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 How It Works\n",
    "\n",
    "The chatbot relies on:\n",
    "- **LLMs (Large Language Models)**: Generate natural, human-like responses.  \n",
    "- **Vector Database (Milvus)**: Stores and retrieves relevant information efficiently.  \n",
    "- **Embeddings**: Converts text into numerical vectors for similarity searches.  \n",
    "- **HTML Parsing**: Processes web pages to extract meaningful content.\n",
    "\n",
    "---\n",
    "\n",
    "### 🐳 Running the Chatbot\n",
    "\n",
    "To set up and run the chatbot:\n",
    "1. Open your terminal.  \n",
    "2. Execute the provided script:\n",
    "   ```bash\n",
    "   bash docker_image_setup.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cee6c4-6460-447e-850b-716514562fa6",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 📦 Step 2: Importing and Explaining Required Libraries\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 📚 Why Are Libraries Important?\n",
    "\n",
    "Python libraries provide ready-made tools to simplify complex tasks. This project uses several specialized libraries to:\n",
    "- Manage database operations.\n",
    "- Load, clean, and process web content.\n",
    "- Embed text into vectors for similarity matching.\n",
    "- Create chat prompts and interactions.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 Required Libraries and Their Purpose\n",
    "\n",
    "Below is a list of the libraries used in this project, along with their purposes:\n",
    "\n",
    "| Library                                         | Purpose                                                                                   |\n",
    "|-------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
    "| `os`                                            | Interface for file and directory operations.                                              |\n",
    "| `pymilvus`                                      | Connect to the **Milvus vector database** and perform database operations.                |\n",
    "| `langchain.chains.combine_documents`            | Combine multiple documents into a single context for chatbot interactions.                |\n",
    "| `langchain.schema.Document`                    | Represent text data along with its metadata.                                              |\n",
    "| `langchain_core.prompts.ChatPromptTemplate`     | Define chatbot prompts and interactions.                                                  |\n",
    "| `langchain_groq.chat_models.ChatGroq`           | Interface for interacting with **Groq’s language model**.                                 |\n",
    "| `langchain_milvus.Milvus`                       | Integrate the **Milvus vector database** with LangChain components.                       |\n",
    "| `langchain_community.document_loaders.RecursiveUrlLoader` | Recursively download content from a website.                                       |\n",
    "| `beautifulsoup4` (`BeautifulSoup`)              | Parse and extract meaningful text from HTML content.                                      |\n",
    "| `langchain_text_splitters.RecursiveCharacterTextSplitter` | Split large text into smaller chunks for processing.                                   |\n",
    "| `langchain_huggingface.HuggingFaceEmbeddings`   | Load pre-trained embedding models to convert text into numerical vectors.                 |\n",
    "\n",
    "---\n",
    "\n",
    "## 📝 Code Snippet: Importing Libraries\n",
    "\n",
    "Here’s how you import these libraries in the code:\n",
    "\n",
    "```python\n",
    "# Import all required libraries for the chatbot\n",
    "\n",
    "# Operating system interface for file/directory operations\n",
    "import os\n",
    "\n",
    "# Milvus database connection and utility functions\n",
    "from pymilvus import connections, utility\n",
    "\n",
    "# LangChain components\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_milvus import Milvus\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Library for parsing HTML content\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7ee76-7fc8-486e-aa45-37b43decbff7",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 🔧 Step 3: Constants and Initial Setup\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "\n",
    "## 🛠️ Defining Key Constants\n",
    "\n",
    "Before diving into the functionality of the chatbot, let’s define the constants used throughout the code. Constants are variables whose values remain unchanged and help make the code more readable and maintainable.\n",
    "\n",
    "Here are the key constants defined in this project:\n",
    "\n",
    "1. **WEBSITE_URL**:  \n",
    "   - Represents the base URL of the website we’ll use as our knowledge base.  \n",
    "   - **Example**: `'https://www.csusb.edu/its'`.  \n",
    "   - This is where the chatbot retrieves its information.\n",
    "\n",
    "2. **DATABASE_PATH**:  \n",
    "   - Specifies the path where the vector database (Milvus) stores its data.  \n",
    "   - **Example**: `'milvus/jupyter_milvus_vector3.db'`.  \n",
    "   - Ensures persistence of knowledge across sessions.\n",
    "\n",
    "3. **EMBEDDING_MODEL**:  \n",
    "   - Name of the pre-trained embedding model used to convert text into numerical vectors for similarity matching.  \n",
    "   - **Example**: `'sentence-transformers/all-MiniLM-L12-v2'`.  \n",
    "   - This model ensures efficient and accurate text embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Code Snippet for Constants\n",
    "\n",
    "Here’s the code defining these constants:\n",
    "\n",
    "```python\n",
    "# URL of the website we'll use as our knowledge base\n",
    "WEBSITE_URL = 'https://www.csusb.edu/its'\n",
    "\n",
    "# Path where we'll store our vector database files\n",
    "DATABASE_PATH = \"milvus/jupyter_milvus_vector3.db\"\n",
    "\n",
    "# Name of the embedding model we'll use to convert text to vectors\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L12-v2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008e28e-4d67-4da6-a4a9-341de4efaf78",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "\n",
    "## 🗄️ Step 4: Setting Up the Vector Database\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "\n",
    "## 📚 What Is a Vector Database?\n",
    "\n",
    "A **vector database** is a specialized database designed to store and retrieve data based on numerical vectors. In this project, we use **Milvus**, an open-source vector database, to:\n",
    "- Efficiently store information from the knowledge base.\n",
    "- Retrieve relevant information for chatbot responses using similarity matching.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Key Functions for Database Setup\n",
    "\n",
    "1. **`setup_vector_database()`**  \n",
    "   - Checks if the vector database is connected and initializes the database.  \n",
    "   - Ensures the collection (a container for vectors) exists or creates one if needed.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Code Snippet: Setting Up the Vector Database\n",
    "\n",
    "Here’s how the database setup is implemented:\n",
    "\n",
    "```python\n",
    "from pymilvus import connections, utility\n",
    "\n",
    "def setup_vector_database(database_path):\n",
    "    \"\"\"Sets up the vector database connection\"\"\"\n",
    "    # Create the parent directory for the database if it doesn't exist\n",
    "    os.makedirs(os.path.split(database_path)[0], exist_ok=True)\n",
    "    \n",
    "    # Connect to the Milvus database using the provided path\n",
    "    connections.connect(\n",
    "        alias=\"default\",        # Use the default connection alias\n",
    "        uri=database_path       # Specify the database location\n",
    "    )\n",
    "    \n",
    "    # Check if the 'IT_support' collection exists\n",
    "    if not utility.has_collection(\"IT_support\"):\n",
    "        print(\"Collection does not exist. You'll need to create it later.\")\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabc0a7-ac1a-4445-a1a5-690e9b26f2ca",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 🔢 Step 5: Setting Up the Embedding Model\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 📚 What Is an Embedding Model?\n",
    "\n",
    "An **embedding model** converts text into numerical vectors that capture the meaning and context of the text. These vectors enable:\n",
    "- **Similarity Matching**: Finding similar texts by comparing vector distances.\n",
    "- **Efficient Retrieval**: Powering search and recommendation systems.\n",
    "\n",
    "In this project, we use the **HuggingFace pre-trained model**:  \n",
    "`sentence-transformers/all-MiniLM-L12-v2`.  \n",
    "This model is lightweight and efficient, making it ideal for chatbot applications.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Key Functions for Embedding Setup\n",
    "\n",
    "1. **`create_embedding_model()`**  \n",
    "   - Initializes and returns the embedding model using the HuggingFace library.  \n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Code Snippet: Creating the Embedding Model\n",
    "\n",
    "Here’s how the embedding model setup is implemented:\n",
    "\n",
    "```python\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def create_embedding_model():\n",
    "    \"\"\"Creates the text embedding model\"\"\"\n",
    "    # Initialize and return a HuggingFace embeddings model\n",
    "    return HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962953e-af57-471f-86c5-9e22e22d7eeb",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 🧹 Step 6: Cleaning and Processing Web Content\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 📚 Why Clean Web Content?\n",
    "\n",
    "When working with data from the web, raw HTML content often contains unnecessary elements like scripts, styles, headers, and footers. Cleaning and processing this content is essential to:\n",
    "- Extract meaningful text.\n",
    "- Remove irrelevant or redundant information.\n",
    "- Prepare data for embedding and retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Key Functions for Cleaning Web Content\n",
    "\n",
    "1. **`clean_webpage_text(html_content)`**  \n",
    "   - Parses raw HTML content.  \n",
    "   - Removes unwanted elements (e.g., `<script>`, `<style>`).  \n",
    "   - Extracts and formats readable text.\n",
    "\n",
    "2. **`download_website_content()`**  \n",
    "   - Uses a recursive URL loader to download pages from a given website.  \n",
    "   - Processes and cleans each page using `clean_webpage_text()`.  \n",
    "   - Converts cleaned text into `Document` objects with metadata.\n",
    "\n",
    "---\n",
    "## 📋 Code Snippets for Cleaning and Processing\n",
    "\n",
    "### Cleaning HTML Content\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_webpage_text(html_content):\n",
    "    \"\"\"Cleans HTML content to extract readable text\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')  # Parse the HTML content\n",
    "    \n",
    "    # Remove unwanted HTML elements\n",
    "    for element in soup(['script', 'style', 'header', 'footer', 'nav']):\n",
    "        element.decompose()\n",
    "    \n",
    "    # Extract main content if available\n",
    "    main_content = soup.find('main')\n",
    "    text = main_content.get_text('\\n') if main_content else soup.get_text('\\n')\n",
    "    \n",
    "    # Clean and format lines\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    return '\\n'.join(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b1f05-0cbd-4922-b9f7-0e3d62b5e735",
   "metadata": {},
   "source": [
    "### Downloading Web Content\n",
    "```python\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "WEBSITE_URL = 'https://www.csusb.edu/its'\n",
    "\n",
    "def download_website_content():\n",
    "    \"\"\"Downloads and processes website content\"\"\"\n",
    "    loader = RecursiveUrlLoader(\n",
    "        url=WEBSITE_URL,  # Starting URL\n",
    "        prevent_outside=True,  # Don't follow links to other domains\n",
    "        base_url=WEBSITE_URL  # Base URL for relative links\n",
    "    )\n",
    "    \n",
    "    # Download pages and clean them\n",
    "    pages = loader.load()\n",
    "    cleaned_pages = []\n",
    "    \n",
    "    for page in pages:\n",
    "        clean_text = clean_webpage_text(page.page_content)\n",
    "        cleaned_pages.append(Document(\n",
    "            page_content=clean_text,\n",
    "            metadata=page.metadata  # Preserve metadata like URL\n",
    "        ))\n",
    "    return cleaned_pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429c71c-a041-44fe-96f4-bb0fe4606105",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## ✂️ Step 7: Splitting Text into Chunks\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 📚 Why Split Text into Chunks?\n",
    "\n",
    "Large text documents can be challenging to process and embed efficiently. Splitting text into manageable chunks:\n",
    "- Reduces memory and processing overhead.\n",
    "- Increases the accuracy of embeddings and similarity matching.\n",
    "- Ensures better retrieval by dividing the information into smaller, focused segments.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Key Function for Splitting Text\n",
    "\n",
    "1. **`split_into_chunks(documents)`**  \n",
    "   - Uses a recursive text splitter to break down cleaned documents into smaller pieces.  \n",
    "   - Configurable chunk size and overlap to optimize text segmentation.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Code Snippet: Splitting Text into Chunks\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_into_chunks(documents):\n",
    "    \"\"\"Splits documents into smaller pieces for processing\"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,        # Maximum size of each text chunk\n",
    "        chunk_overlap=300,      # Overlap between chunks for context continuity\n",
    "        is_separator_regex=False  # Disable regex-based splitting\n",
    "    )\n",
    "    return splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1dcaf-01fd-4d56-be58-3b96c6aa3c9f",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 💬 Step 8: Creating Chatbot Prompts\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 📚 Why Are Prompts Important?\n",
    "\n",
    "A **prompt** defines how the chatbot interacts with users and generates responses. In this project, prompts are used to:\n",
    "- Guide the chatbot’s behavior.\n",
    "- Structure the interaction by providing clear instructions and context.\n",
    "- Ensure that responses are accurate and aligned with the provided knowledge base.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Key Function for Creating Prompts\n",
    "\n",
    "1. **`create_chatbot_prompt()`**  \n",
    "   - Defines a system message to establish the chatbot’s behavior.  \n",
    "   - Includes a human message template to structure the user’s input and the chatbot’s context.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Code Snippet: Defining the Chatbot Prompt\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def create_chatbot_prompt():\n",
    "    \"\"\"Creates the instruction prompt for the chatbot\"\"\"\n",
    "    system_message = \"\"\"\n",
    "    You are an AI assistant that provides answers strictly based on the provided context. Adhere to these guidelines:\n",
    "     - Only answer questions based on the content within the <context> tags.\n",
    "     - If the <context> doesn't contain relevant information, respond with: \"I don't have enough information to answer this question.\"\n",
    "     - Ask for clarification if questions are unclear.\n",
    "     - Provide specific, concise answers with relevant statistics when available.\n",
    "     - Don't add external information or make assumptions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a prompt template with system and human messages\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_message),  # Define the chatbot's behavior\n",
    "        (\"human\", \"<question>{input}</question>\\n\\n<context>{context}</context>\")  # Structure user input and context\n",
    "    ])\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db666e-5b56-455c-a7dc-11621d2390fc",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 🤖 Step 9: Initializing the Chatbot\n",
    "\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 📚 Why Initialize the Chatbot?\n",
    "\n",
    "Initialization combines all the components we've built so far—vector database, embedding model, and prompts—into a cohesive system. This step:\n",
    "- Connects the chatbot to the database and embedding model.\n",
    "- Sets up a retrieval mechanism to fetch relevant data.\n",
    "- Configures the chatbot for seamless interaction with users.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Key Function for Initialization\n",
    "\n",
    "1. **`initialize_chatbot(api_key)`**  \n",
    "   - Sets up the language model, vector database, and retrieval chain.  \n",
    "   - Combines these components to create a fully functional chatbot.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Code Snippet: Initializing the Chatbot\n",
    "\n",
    "```python\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langchain_milvus import Milvus\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "def initialize_chatbot(api_key):\n",
    "    \"\"\"Sets up all components needed for the chatbot\"\"\"\n",
    "    # Initialize the language model with configuration\n",
    "    model = ChatGroq(\n",
    "        model=\"llama-3.1-70b-versatile\",  # Language model version\n",
    "        temperature=0.9,                 # Response variability\n",
    "        api_key=api_key                  # API key for authentication\n",
    "    )\n",
    "    \n",
    "    # Check if the vector database is already set up\n",
    "    if setup_vector_database(DATABASE_PATH):\n",
    "        vector_store = Milvus(\n",
    "            collection_name=\"IT_support\",\n",
    "            embedding_function=create_embedding_model(),\n",
    "            connection_args={\"uri\": DATABASE_PATH}\n",
    "        )\n",
    "        print(\"Loading existing knowledge base...\")\n",
    "    else:\n",
    "        print(\"Creating new knowledge base...\")\n",
    "        documents = download_website_content()\n",
    "        chunks = split_into_chunks(documents)\n",
    "        vector_store = Milvus.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=create_embedding_model(),\n",
    "            collection_name=\"IT_support\",\n",
    "            connection_args={\"uri\": DATABASE_PATH},\n",
    "            drop_old=True\n",
    "        )\n",
    "    \n",
    "    # Create a retriever for fetching documents\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",  # Maximal Marginal Relevance for diversity\n",
    "        search_kwargs={\"score_threshold\": 1, \"k\": 3}\n",
    "    )\n",
    "    \n",
    "    # Combine the retriever and prompt into a retrieval chain\n",
    "    document_chain = create_stuff_documents_chain(model, create_chatbot_prompt())\n",
    "    return create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c8f3f-4964-4b64-b750-85069fd2a7f0",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a>\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "## 🏁 Step 10: Creating the Main Function\n",
    "<div style=\"border-top: 8px solid black; margin: 20px 0;\"></div>\n",
    "\n",
    "\n",
    "## 📚 Why a Main Function?\n",
    "\n",
    "The **main function** ties all components together and serves as the user interface for the chatbot. It:\n",
    "- Provides a seamless way to interact with the chatbot.\n",
    "- Handles user inputs and generates responses.\n",
    "- Offers a clear entry point for running the entire application.\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Key Function for the Main Program\n",
    "\n",
    "1. **`main()`**  \n",
    "   - Prompts the user for their API key and initializes the chatbot.  \n",
    "   - Continuously accepts user queries and provides responses until the user exits.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Code Snippet: The Main Function\n",
    "\n",
    "```python\n",
    "def main():\n",
    "    \"\"\"Main program loop\"\"\"\n",
    "    print(f\"Welcome to the CSUSB ITS Support Chatbot!\\nThis bot answers questions about: {WEBSITE_URL}\")\n",
    "    \n",
    "    try:\n",
    "        # Get API key from user\n",
    "        api_key = get_api_key()\n",
    "        \n",
    "        # Initialize the chatbot\n",
    "        chain = initialize_chatbot(api_key)\n",
    "        \n",
    "        # Start interaction loop\n",
    "        while True:\n",
    "            question = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
    "            \n",
    "            if question.lower() == 'exit':\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            # Get response from the chatbot\n",
    "            answer = answer_question(chain, question)\n",
    "            print(\"\\nResponse:\", answer)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nGoodbye!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {str(e)}\")\n",
    "        print(\"Please restart the program and try again.\")\n",
    "\n",
    "# Run the program if this file is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e192a-5f13-43f2-b537-40f27ad6cf74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
